import requests
import pandas as pd

items = []
next_url = f"https://graph.microsoft.com/v1.0/sites/{site_id}/lists/{list_id}/items?$expand=fields&$top=100"

while next_url:
    response = requests.get(next_url, headers=headers)
    response.raise_for_status()
    data = response.json()
    for item in data.get("value", []):
        row = item.get("fields", {}).copy()
        for k, v in list(row.items()):
            # Flatten person/lookup fields with list of dicts
            if isinstance(v, list):
                names = []
                for entry in v:
                    if isinstance(entry, dict):
                        name = entry.get("lookupValue") or entry.get("displayName") or entry.get("title") or entry.get("email")
                        if name:
                            names.append(str(name))
                row[k + "_names"] = ", ".join(names)
                del row[k]
            # Flatten single person/lookup object
            elif isinstance(v, dict):
                name = v.get("lookupValue") or v.get("displayName") or v.get("title") or v.get("email")
                if name:
                    row[k + "_name"] = str(name)
                    del row[k]
        items.append(row)
    next_url = data.get("@odata.nextLink")

# Save to DataFrame and CSV
df = pd.DataFrame(items)
df.to_csv("sharepoint_list_items.csv", index=False)
print("âœ… Data written to sharepoint_list_items.csv")
